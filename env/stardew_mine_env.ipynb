{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f763b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt install python-opengl\n",
    "!apt install ffmpeg\n",
    "!apt install xvfb\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install pyglet==1.5.1\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f0819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISPLAY is set ( /private/tmp/com.apple.launchd.QwM2NASdGv/org.xquartz:0 ) â€” using existing display\n"
     ]
    }
   ],
   "source": [
    "# Virtual display\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "412005d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /opt/anaconda3/envs/hw2-py310/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/envs/hw2-py310/lib/python3.10/site-packages (from gymnasium) (2.2.6)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/anaconda3/envs/hw2-py310/lib/python3.10/site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/envs/hw2-py310/lib/python3.10/site-packages (from gymnasium) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/envs/hw2-py310/lib/python3.10/site-packages (from gymnasium) (0.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ce991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import numpy as np\n",
    "if not hasattr(np, \"bool8\"):\n",
    "  np.bool8 = np.bool_\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# Gym\n",
    "import gymnasium as gym\n",
    "#import gym_pygame\n",
    "\n",
    "# Hugging Face Hub\n",
    "# from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
    "# import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c14af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StardewMineEv(gym.Env):\n",
    "    def __init__(self, size: int = 10, max_floor: int = 10, max_energy: int = 100, local_view_size: int = 5, seed: Optional[int] = None):\n",
    "        # The size of the square grid (10x10 by default)\n",
    "        self.SIZE = size\n",
    "        self.MAX_FLOOR = max_floor\n",
    "        self.MAX_ENERGY = max_energy\n",
    "        self.LOCAL_VIEW_SIZE = local_view_size  # Agent can see everything in the surrounding nxn area; n odd\n",
    "        \n",
    "        # Initialize state variables\n",
    "        self.agent_location = np.array([-1, -1], dtype=np.int32)\n",
    "        self.grid = None  # (size x size) grid\n",
    "        self.energy = None\n",
    "        self.floor = None\n",
    "        self._ladder_location = None  # (y, x)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Initialize tile types\n",
    "        self.EMPTY = 0\n",
    "        self.LADDER = 1\n",
    "        self.WEED = 2\n",
    "        self.ROCK = 3\n",
    "        self.ORE = 4  # TODO: add more ores\n",
    "        self.OUT_OF_BOUND = -1\n",
    "        self.MAX_TILE_TYPE = 4\n",
    "\n",
    "        self.AGENT = 9  # Render ONLY\n",
    "\n",
    "        # Initialize action space\n",
    "        self.action_space = gym.spaces.Discrete(17)\n",
    "        self.ACTION_MOVE_RIGHT = 0\n",
    "        self.ACTION_MOVE_UP_RIGHT = 1\n",
    "        self.ACTION_MOVE_UP = 2\n",
    "        self.ACTION_MOVE_UP_LEFT = 3\n",
    "        self.ACTION_MOVE_LEFT = 4\n",
    "        self.ACTION_MOVE_DOWN_LEFT = 5\n",
    "        self.ACTION_MOVE_DOWN = 6\n",
    "        self.ACTION_MOVE_DOWN_RIGHT = 7\n",
    "        self.ACTION_MINE_RIGHT = 8\n",
    "        self.ACTION_MINE_UP_RIGHT = 9\n",
    "        self.ACTION_MINE_UP = 10\n",
    "        self.ACTION_MINE_UP_LEFT = 11\n",
    "        self.ACTION_MINE_LEFT = 12\n",
    "        self.ACTION_MINE_DOWN_LEFT = 13\n",
    "        self.ACTION_MINE_DOWN = 14\n",
    "        self.ACTION_MINE_DOWN_RIGHT = 15\n",
    "        self.ACTION_DESCEND = 16\n",
    "        \n",
    "\n",
    "        # Map action numbers to actual movements on the grid\n",
    "        # This makes the code more readable than using raw numbers\n",
    "        self._action_to_direction = {\n",
    "            self.ACTION_MOVE_RIGHT: np.array([1, 0]),\n",
    "            self.ACTION_MOVE_UP_RIGHT: np.array([1, -1]),\n",
    "            self.ACTION_MOVE_UP: np.array([0, -1]),\n",
    "            self.ACTION_MOVE_UP_LEFT: np.array([-1, -1]),\n",
    "            self.ACTION_MOVE_LEFT: np.array([-1, 0]),\n",
    "            self.ACTION_MOVE_DOWN_LEFT: np.array([-1, 1]),\n",
    "            self.ACTION_MOVE_DOWN: np.array([0, 1]),\n",
    "            self.ACTION_MOVE_DOWN_RIGHT: np.array([1, 1]),\n",
    "        }\n",
    "\n",
    "        # Initialize observation space\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            {\n",
    "                \"agent_location\": gym.spaces.Box(0, self.SIZE - 1, shape=(2,), dtype=np.int32),\n",
    "                \"energy\": gym.spaces.Box(0, self.MAX_ENERGY, shape=(), dtype=np.int32),\n",
    "                \"floor\": gym.spaces.Box(0, self.MAX_FLOOR - 1, shape=(), dtype=np.int32),\n",
    "                \"local_view\": gym.spaces.Box(self.OUT_OF_BOUND, self.MAX_TILE_TYPE, shape=(self.LOCAL_VIEW_SIZE, self.LOCAL_VIEW_SIZE), dtype=np.int32),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    \n",
    "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        \"\"\"Start a new episode.\n",
    "\n",
    "        Args:\n",
    "            seed: Random seed for reproducible episodes\n",
    "            options: Additional configuration (unused in this example)\n",
    "\n",
    "        Returns:\n",
    "            tuple: (observation, info) for the initial state\n",
    "        \"\"\"\n",
    "        # IMPORTANT: Must call this first to seed the random number generator\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Randomly place the agent anywhere on the top row of the grid\n",
    "        self.agent_location = self.np_random.integers(0, self.SIZE, size=2, dtype=np.int32)\n",
    "        self.energy = self.MAX_ENERGY\n",
    "        self.floor = 0\n",
    "\n",
    "        # Generate floor rewards and obstacles\n",
    "        self._generate_floor()  # TODO: generate floor with weed vs. no weed\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "\n",
    "    def step(self, action: int):\n",
    "        \"\"\"Execute one timestep within the environment.\n",
    "\n",
    "        Args:\n",
    "            action: The action to take (0-3 for directions)\n",
    "\n",
    "        Returns:\n",
    "            tuple: (observation, reward, terminated, truncated, info)\n",
    "        \"\"\"\n",
    "\n",
    "        reward = 0.0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "\n",
    "        # DESCEND (16)\n",
    "        if action == self.ACTION_DESCEND:\n",
    "            if self.floor < self.MAX_FLOOR-1 and self._ladder_location is not None:\n",
    "                ax, ay = self.agent_location\n",
    "                lx, ly = self._ladder_location\n",
    "                # Go to next floor if ladder is within 3x3 area\n",
    "                if abs(lx - ax) <= 1 and abs(ly - ay) <= 1:\n",
    "                    self.floor += 1\n",
    "                    self._generate_floor()\n",
    "                    reward += 0.5  # TODO: adjust\n",
    "\n",
    "        # MINE (8-15): mine 1 tile in a direction\n",
    "        elif 8 <= action <= 15:\n",
    "            reward += self._mine_tile(action)\n",
    "\n",
    "        # MOVE (0-7)\n",
    "        else:\n",
    "            direction = self._action_to_direction[action]\n",
    "\n",
    "            # Update agent position, ensuring it stays within grid bounds\n",
    "            # np.clip prevents the agent from walking off the edge\n",
    "            agent_location = np.clip(\n",
    "                self.agent_location + direction, 0, self.SIZE - 1\n",
    "            )\n",
    "\n",
    "            # If tile is empty, move agent\n",
    "            if self.grid[agent_location[1], agent_location[0]] == 0:\n",
    "                self.agent_location = agent_location\n",
    "                reward -= 0.05\n",
    "            else:\n",
    "                reward -= 0.5  # Penalize agent for wasting movement\n",
    "\n",
    "        # End episode when all rocks/ores in the last floor are collected OR when agent collapses\n",
    "        if self._is_grid_empty():\n",
    "            terminated = True\n",
    "            reward += 5  # TODO: adjust\n",
    "        elif self.energy <= 0:\n",
    "            terminated = True\n",
    "            reward -= 10  # TODO: adjust\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    \n",
    "    def _generate_floor(self):\n",
    "        self.grid = np.full((self.SIZE, self.SIZE), self.EMPTY, dtype=np.int32)\n",
    "\n",
    "        # Get environment spawn probability\n",
    "        prob_weed, prob_rock, prob_ore = 0.1, 0.3, 0.05\n",
    "\n",
    "        possible_ladder_locations = []\n",
    "\n",
    "        for y in range(self.SIZE):\n",
    "            for x in range(self.SIZE):\n",
    "                if (x,y) == tuple(self.agent_location):\n",
    "                    continue\n",
    "                i = np.random.random()\n",
    "                if i < prob_weed:\n",
    "                    self.grid[y,x] = self.WEED\n",
    "                elif i < prob_weed + prob_rock:\n",
    "                    self.grid[y,x] = self.ROCK\n",
    "                    possible_ladder_locations.append((y,x))\n",
    "                elif i < prob_weed + prob_rock + prob_ore:\n",
    "                    self.grid[y,x] = self.ORE\n",
    "                    possible_ladder_locations.append((y,x))\n",
    "\n",
    "        # Ensure that there's at least 1 rock in each floor to place the ladder\n",
    "        # and also avoid placing rock under agent\n",
    "        if not possible_ladder_locations:\n",
    "            while True:\n",
    "                x = np.random.randint(0, self.SIZE)\n",
    "                y = np.random.randint(0, self.SIZE)\n",
    "                if (x,y) != tuple(self.agent_location) and self.grid[y,x] == self.EMPTY:\n",
    "                    self.grid[y,x] = self.ROCK\n",
    "                    possible_ladder_locations.append((x,y))\n",
    "                    break\n",
    "\n",
    "        # Place ladder under a randomly chosen rock/ore if not at last floor\n",
    "        if self.floor < self.MAX_FLOOR - 1:\n",
    "            self._ladder_location = np.random.choice(possible_ladder_locations)\n",
    "        else:\n",
    "            self._ladder_location = None\n",
    "\n",
    "\n",
    "    def _mine_tile(self, action: int):\n",
    "        reward = 0.0\n",
    "        self.energy -= 1\n",
    "\n",
    "        direction = self._action_to_direction[action-8]\n",
    "        x, y = self.agent_location + direction\n",
    "\n",
    "        # If mine out of bounds, do nothing, and penalize for wasting movement\n",
    "        if not (0 <= x < self.SIZE and 0 <= y < self.SIZE):\n",
    "            return reward - 1\n",
    "\n",
    "        tile = self.grid[y,x]\n",
    "\n",
    "        match tile:\n",
    "            case self.ORE:  # TODO: add more ore values\n",
    "                reward += 1\n",
    "            case self.EMPTY:  # Penalize agent for mining empty space\n",
    "                reward -= 1\n",
    "            case _:\n",
    "                reward -= 0.01  # TODO: consider different rewards/penalty for rocks vs. weeds\n",
    "        # Tile is empty after being mined\n",
    "        self.grid[y,x] = self.EMPTY\n",
    "\n",
    "        if self._ladder_location is not None and (y,x) == self._ladder_location:\n",
    "            self.grid[y,x] = self.LADDER\n",
    "\n",
    "        return reward\n",
    "\n",
    "\n",
    "    def _is_grid_empty(self):\n",
    "        return np.sum(self.grid) == 0\n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        half = self.LOCAL_VIEW_SIZE // 2\n",
    "        x,y = self.agent_location\n",
    "        x_lower, x_upper, y_lower, y_upper = max(0, x-2), min(self.SIZE, x+half+1), max(0, y-2), min(self.SIZE, y+half+1)\n",
    "        local_view = np.full((self.LOCAL_VIEW_SIZE, self.LOCAL_VIEW_SIZE), self.OUT_OF_BOUND, dtype=np.int32)\n",
    "        # Patch to cover cases where local_view is not 5x5 (due to agent near edge, corner, etc.)\n",
    "        patch = self.grid[y_lower:y_upper, x_lower:x_upper]\n",
    "        # Shift patched grid so that agent is at center\n",
    "        local_view[(y_lower-(y-half)):(y_upper-(y-half)), (x_lower-(x-half)):(x_upper-(x-half))] = patch\n",
    "\n",
    "        obs = {\n",
    "            \"agent_location\": self.agent_location.copy(),\n",
    "            \"energy\": np.int32(self.energy),\n",
    "            \"floor\": np.int32(self.floor),\n",
    "            \"local_view\": local_view\n",
    "        }\n",
    "        return obs\n",
    "\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {}\n",
    "\n",
    "\n",
    "    def render(self, render_mode: str = \"human\"):\n",
    "        grid_copy = self.grid.copy()\n",
    "        x,y = self.agent_location\n",
    "        grid_copy[y,x] = 9  # Agent\n",
    "        print(\"Floor:\", self.floor, \"Energy:\", self.energy)\n",
    "        print(grid_copy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
